{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b6e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afa66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install daal==2021.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea76e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307671b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6997f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f31895",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'UrbanSound8K/dog_bark.wav'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ccfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "librosa_data, sample_rate = librosa.load(filename)\n",
    "librosa.display.waveshow(librosa_data, sr=sample_rate)\n",
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(librosa_data.shape)\n",
    "librosa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "\n",
    "wav_sample_rate, wav_data = wav.read(filename)\n",
    "wav_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c43416",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a68055",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = metadata.index[metadata['slice_file_name']=='34050-7-5-0.wav']\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b58f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.iloc[6133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445981b7",
   "metadata": {},
   "source": [
    "# Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_data, sr=sample_rate, n_mfcc=40)  # mfcc--> Mel-Feature Cepstrum Coefficients\n",
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(filename):\n",
    "    audio_data, sample_rate = librosa.load(filename)\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbd7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset_path = 'UrbanSound8K/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "extracted_features = []\n",
    "for idx, row in tqdm(metadata.iterrows()):\n",
    "    filename = os.path.join(os.path.abspath(audio_dataset_path), 'fold'+str(row['fold'])+'/'+str(row['slice_file_name']))\n",
    "    class_label = row['class']\n",
    "    data = feature_extractor(filename)\n",
    "    extracted_features.append([data,class_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['features', 'class'])\n",
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(extracted_features_df['features'].tolist())\n",
    "y= np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4827eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = pd.get_dummies(y)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = labelencoder.fit_transform(y)\n",
    "a = pd.DataFrame(a)\n",
    "a[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y = to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a60b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64453d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tuner,X_val,y_train_tuner,y_val = train_test_split(X_train,y_train,test_size=0.2, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5edef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tuner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ffa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tuner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30901321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75a910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3edd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03440db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 10)):\n",
    "        model.add(layers.Dense(hp.Int(f'units_{i}', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "        if hp.Boolean(f'dropout_{i}'):\n",
    "            model.add(layers.Dropout(0.25))\n",
    "            \n",
    "    model.add(layers.Dense(units=total_labels, activation='softmax'))\n",
    "              \n",
    "    learning_rate = hp.Float('ls', min_value=0.00001, max_value=0.001, sampling='log')\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "              \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2535ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    directory=\"F:\",\n",
    "    project_name=\"tuned_ANN_speech\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99c218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(X_train_tuner, y_train_tuner, epochs=50, validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb224089",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fa6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 40))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cbd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e343f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best epoch\n",
    "# Epoch 94/100\n",
    "# 110/110 [==================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9930 - val_loss: 0.3895 - val_accuracy: 0.9393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ANN_hypertuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4f1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c6710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc620b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model = Sequential()\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in range(0,7):\n",
    "    model.add(layers.Dense(units= 280 + (i*10), activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "\n",
    "model.add(layers.Dense(units=total_labels, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=6.023588532722681e-05), loss='categorical_crossentropy', metrics=['accuracy'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddda1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test,y_test))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa637d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = 'UrbanSound8K/mixkit-laser-weapon-shot-1681.wav'\n",
    "audio_data = feature_extractor(filenames)\n",
    "audio_data = audio_data.reshape(1,-1)\n",
    "predicted_label = np.argmax(model.predict(audio_data), axis=-1)\n",
    "print(predicted_label)\n",
    "predicted_class = labelencoder.inverse_transform(predicted_label)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd0c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69704f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5be08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trial 03 summary\n",
    "Hyperparameters:\n",
    "num_layers: 7\n",
    "units: 352\n",
    "dropout: False\n",
    "ls: 6.023588532722681e-05\n",
    "Score: 0.9126700162887573'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model = Sequential([\n",
    "    \n",
    "    Dense(units=100, activation= 'relu', input_shape = (40,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=200, activation= 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=100, activation= 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=total_labels, activation= 'softmax')\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b81605",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "num_epochs = 100\n",
    "num_batch = 32\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch, epochs=num_epochs, validation_data=(X_test,y_test), callbacks=[checkpoint])\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Total Training Time: \",duration)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_accuracy[1]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filenames = 'UrbanSound8K/mixkit-laser-weapon-shot-1681.wav'\n",
    "audio_data = feature_extractor(filenames)\n",
    "audio_data = audio_data.reshape(1,-1)\n",
    "predicted_label = np.argmax(model.predict(audio_data), axis=-1)\n",
    "print(predicted_label)\n",
    "predicted_class = labelencoder.inverse_transform(predicted_label)\n",
    "predicted_class'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c61d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e383d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
